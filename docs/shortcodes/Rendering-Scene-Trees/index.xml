<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computación visual</title><link>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/</link><description>Recent content on Computación visual</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/1.-Rasterizaci%C3%B3n/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/1.-Rasterizaci%C3%B3n/</guid><description>[Rasterización] #</description></item><item><title/><link>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/2.-Tecnicas-de-interacci%C3%B3n-3D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/2.-Tecnicas-de-interacci%C3%B3n-3D/</guid><description>Estudio de las técnicas de interacción para entornos 3D interactivos # Revisión de las técnicas de interacción no inmersivas para la navegación, la selección y la manipulación, y el control del sistema. Se espera ayudar a los investigadores y desarrolladores de aplicaciones 3D interactivas, a que tengan una visión más clara del tema y en particular a los nuevos aprendices de aplicaciones interactivas en 3D.
Introducción # A pesar de que las personas pasan toda su vida en un mundo 3D les resulta difícil interactuar en entornos 3D interactivos.</description></item><item><title/><link>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/3.-Main-Spaces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gapuentesr.github.io/VisualComputing/docs/shortcodes/Rendering-Scene-Trees/3.-Main-Spaces/</guid><description>PoseNet # ¿Qués es PoseNet? # PoseNet es un modelo TensorFlow de aprendizaje profundo que permite estimar la pose humana en tiempo real (con imágen o video) al detectar partes del cuerpo como codos, caderas, muñecas, rodillas, tobillos y formar una estructura esquelética de su pose al unir estos puntos.
PoseNet brinda un total de 17 puntos clave que se pueden usar, desde el ojo hasta los oídos, las rodillas y los tobillos.</description></item></channel></rss>